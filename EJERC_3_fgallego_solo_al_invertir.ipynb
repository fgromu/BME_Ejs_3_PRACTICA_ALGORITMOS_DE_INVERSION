{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c11b6-4023-4cf8-8b2f-c23b10a0db60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e12c56d-6f29-483c-897f-3d3a2400417c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CELDA DE INICIALIZACION DE class BMEApiHandler\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from dateutil.parser import parse # nuevo pq me daba error el parse\n",
    "from datetime import datetime\n",
    "#%%\n",
    "\n",
    "\n",
    "#Refactoriza el código en una clase para el algoritmo y otra para un handler del API.\n",
    "class BMEApiHandler:\n",
    "\n",
    "    def __init__(self):#El constructor que se inicializaba cunado se construia la clase. \n",
    "        #Self nos ayuda a almacenar la inforamcion que necesitqabamos\n",
    "        self.url_base = 'https://miax-gateway-jog4ew3z3q-ew.a.run.app'\n",
    "        self.competi = 'mia_9'\n",
    "        self.user_key = 'AIzaSyDHpqtr1hgF2UpGxPtpv2iWKdxVsKCIr14'\n",
    "\n",
    "    #1. Descarga el maestro de valores. TICKER_MASTER\n",
    "    def get_ticker_master(self, market):\n",
    "        url = f'{self.url_base}/data/ticker_master'\n",
    "        params = {'competi': self.competi,\n",
    "                'market': market,\n",
    "                'key': self.user_key}\n",
    "        response = requests.get(url, params)\n",
    "        tk_master = response.json()\n",
    "        maestro_df = pd.DataFrame(tk_master['master'])\n",
    "        return maestro_df\n",
    "    \n",
    "    #2.Descarga todos los datos para cada ticker del maestro. TIME_SERIES. Baja solo el close.\n",
    "    #Devuelve una serie\n",
    "    def get_close_data(self, market, tck): \n",
    "        url = f'{self.url_base}/data/time_series'\n",
    "        params = {\n",
    "            'market': market,\n",
    "            'key': self.user_key,\n",
    "            'ticker': tck\n",
    "        }\n",
    "        response = requests.get(url, params)\n",
    "        #poner aqui lo de que de 200 pq si no ha habido uan carga incorrecta de datos\n",
    "        #print(response.status_code)\n",
    "        ########print(response.close)\n",
    "        #print(response.content)\n",
    "        #print(response.text)\n",
    "        tk_data = response.json()\n",
    "        series_data = pd.read_json(tk_data, typ='series')\n",
    "        return series_data\n",
    "    \n",
    "    #2.1 #2.Descarga todos los datos para cada ticker del maestro. No solo el close\n",
    "    def get_ohlc_data(self, market, tck): \n",
    "        url = f'{self.url_base}/data/time_series'\n",
    "        params = {\n",
    "            'market': market,\n",
    "            'key': self.user_key,\n",
    "            'ticker': tck,\n",
    "            'close': False\n",
    "        }\n",
    "        response = requests.get(url, params)\n",
    "        tk_data = response.json()\n",
    "        df_data = pd.read_json(tk_data, typ='frame')\n",
    "        return df_data\n",
    "    \n",
    "    #funcion para mandar al programa de miax los tickers con las alocaciones y los dias por simulacion\n",
    "    def send_alloc(self, algo_tag, market, str_date, allocation):\n",
    "        url = f'{self.url_base}/participants/allocation'\n",
    "        url_auth = f'{url}?key={self.user_key}'\n",
    "        ####print(url_auth)  # Luego lo pongo. Lo que quitado pra que el error me apareciera limpio\n",
    "        params = {\n",
    "            'competi': self.competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "            'date': str_date,\n",
    "            'allocation': allocation\n",
    "        }\n",
    "        #print(json.dumps(params))\n",
    "        response = requests.post(url_auth, data=json.dumps(params))\n",
    "        print(\"send_alloc:\",response.json()) # nos dice si se ha insertado correctamente o no\n",
    "        a=response.json()\n",
    "        if a == {'message': 'Asignacion mayor del 100%'}:\n",
    "            print(url_auth, json.dumps(params))\n",
    "        #print(response.close) # nuevo para ver si se ha enviado bien\n",
    "    \n",
    "    #funcion para saber cuales son mis algo_tag. Ya los conozco. No es neceasrio usarlo\n",
    "    def get_algos(self):\n",
    "        url = f'{self.url_base}/participants/algorithms'\n",
    "        params = {'competi': self.competi,\n",
    "                'key': self.user_key}\n",
    "        response = requests.get(url, params)\n",
    "        algos = response.json()\n",
    "        if algos:\n",
    "            algos_df = pd.DataFrame(algos)\n",
    "            return algos_df\n",
    "    \n",
    "    #5. Recuper/me muestra el post de estos allocations que se environ anteriormente\n",
    "    def allocs_to_frame(self, json_allocations):\n",
    "        alloc_list = []\n",
    "        for json_alloc in json_allocations:\n",
    "            #print(json_alloc)\n",
    "            allocs = pd.DataFrame(json_alloc['allocations'])\n",
    "            allocs.set_index('ticker', inplace=True)\n",
    "            alloc_serie = allocs['alloc']\n",
    "            alloc_serie.name = json_alloc['date'] \n",
    "            alloc_list.append(alloc_serie)\n",
    "        all_alloc_df = pd.concat(alloc_list, axis=1).T\n",
    "        return all_alloc_df\n",
    "    \n",
    "    #6. Usa la API para obtener todas las allocations introducidas.\n",
    "    #NO ESTA HECHO CON EL CONTROL DE ERRORES. SI NO HAY ALOCACIONES VA A CASCAR EL PROGRAMA\n",
    "    def get_allocations(self, algo_tag, market):\n",
    "        url = f'{self.url_base}/participants/algo_allocations'\n",
    "        params = {\n",
    "            'key': self.user_key,\n",
    "            'competi': self.competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "        }\n",
    "        response = requests.get(url, params)\n",
    "        df_allocs = self.allocs_to_frame(response.json())\n",
    "        return df_allocs\n",
    "    \n",
    "    #7. Usa la API para ejecutar el backtesting.\n",
    "    def backtest_algo(self, algo_tag, market):\n",
    "        url = f'{self.url_base}/participants/exec_algo'\n",
    "        url_auth = f'{url}?key={self.user_key}'\n",
    "        params = {\n",
    "            'competi': self.competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "            }\n",
    "        response = requests.post(url_auth, data=json.dumps(params))\n",
    "        if response.status_code == 200:   ### 200 entiendo que es el codigo que todo ha ido bien\n",
    "            exec_data = response.json()\n",
    "            status = exec_data.get('status')\n",
    "            res_data = exec_data.get('content')\n",
    "            if res_data:\n",
    "                performace = pd.Series(res_data['result'])\n",
    "                trades = pd.DataFrame(res_data['trades'])\n",
    "                return performace, trades\n",
    "        else:\n",
    "            exec_data = dict()\n",
    "            print(\"backtest_algo:\",response.text)\n",
    "    \n",
    "    #8. Elimina todas las allocations.\n",
    "    def delete_allocs(self, algo_tag, market):\n",
    "        url = f'{self.url_base}/participants/delete_allocations'\n",
    "        url_auth = f'{url}?key={self.user_key}'\n",
    "        params = {\n",
    "            'competi': self.competi,\n",
    "            'algo_tag': algo_tag,\n",
    "            'market': market,\n",
    "            }\n",
    "        response = requests.post(url_auth, data=json.dumps(params))\n",
    "        print(\"delete_allocs:\",response.text)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d373dbda-dfa7-42bb-850c-89447e849f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66f4e8bc-15fc-4207-8b81-5a3b6238175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#2. HierarchicalRiskParity del profesor del Santander. PARECE QUE FUNCIONA\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import inv,pinv\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from datetime import timedelta \n",
    "import matplotlib.pyplot as mpl \n",
    "import scipy.cluster.hierarchy as sch,random,numpy as np,pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Defino las funciones para la optimización del presupuesto de riesgo\n",
    "#------------------------------------------------------------------------------ \n",
    "def getIVP(cov,**kargs): \n",
    "    # Compute the inverse-variance portfolio \n",
    "    ivp=1./np.diag(cov)\n",
    "    ivp/=ivp.sum() \n",
    "    return ivp \n",
    "#------------------------------------------------------------------------------ \n",
    "def getClusterVar(cov,cItems): \n",
    "    # Compute variance per cluster \n",
    "    cov_=cov.loc[cItems,cItems]\n",
    "    # matrix slice \n",
    "    w_=getIVP(cov_).reshape(-1,1)\n",
    "    cVar=np.dot(np.dot(w_.T,cov_),w_)[0,0]\n",
    "    return cVar \n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def getQuasiDiag(link): \n",
    "    # Sort clustered items by distance \n",
    "    link=link.astype(int) \n",
    "    sortIx=pd.Series([link[-1,0],link[-1,1]])\n",
    "    numItems=link[-1,3] \n",
    "    # number of original items \n",
    "    while sortIx.max()>=numItems:\n",
    "        sortIx.index=range(0,sortIx.shape[0]*2,2) # make space\n",
    "        df0=sortIx[sortIx>=numItems] # find clusters\n",
    "        i=df0.index;j=df0.values-numItems\n",
    "        sortIx[i]=link[j,0] # item 1 \n",
    "        df0=pd.Series(link[j,1],index=i+1)\n",
    "        #sortIx=sortIx.append(df0) # item 2 #ESTO DA UN WARNING\n",
    "        sortIx= pd.concat([sortIx, df0]) # lo sustituyo por este para qeuitar la alarma y parace que funciona\n",
    "        \n",
    "        sortIx=sortIx.sort_index() # re-sort\n",
    "        sortIx.index=range(sortIx.shape[0])\n",
    "        # re-index \n",
    "        \n",
    "    return sortIx.tolist()\n",
    "#------------------------------------------------------------------------------\n",
    "def getRecBipart(cov,sortIx):\n",
    "    # Compute HRP alloc \n",
    "    w=pd.Series(1,index=sortIx)\n",
    "    cItems=[sortIx] # initialize all items in one cluster \n",
    "    while len(cItems)>0: \n",
    "        cItems=[i[j:k] for i in cItems for j,k in ((0,len(i)//2),(len(i)//2,len(i))) if len(i)>1] # bi-section\n",
    "        for i in range(0,len(cItems),2): # parse in pairs\n",
    "            cItems0=cItems[i] # cluster 1 \n",
    "            cItems1=cItems[i+1] # cluster 2\n",
    "            cVar0=getClusterVar(cov,cItems0) \n",
    "            cVar1=getClusterVar(cov,cItems1) \n",
    "            alpha=1-cVar0/(cVar0+cVar1)\n",
    "            w[cItems0]*=alpha # weight 1 \n",
    "            w[cItems1]*=1-alpha # weight 2 \n",
    "    return w\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "def correlDist(corr): # A distance matrix based on correlation, where 0<=d[i,j]<=1 # This is a proper distance metric\n",
    "    dist=((1-corr)/2.)**.5 # distance matrix\n",
    "    return dist \n",
    "#------------------------------------------------------------------------------ \n",
    "def correlDist(corr): # A distance matrix based on correlation, where 0<=d[i,j]<=1 # This is a proper distance metric\n",
    "    dist=((1-corr)/2.)**.5 # distance matrix\n",
    "    return dist \n",
    "#------------------------------------------------------------------------------ \n",
    "def plotCorrMatrix(corr,labels=None): # Heatmap of the correlation matrix if labels is None:\n",
    "    labels=[] \n",
    "    mpl.pcolor(corr)\n",
    "    mpl.colorbar() \n",
    "    mpl.yticks(np.arange(.5,corr.shape[0]+.5),labels)\n",
    "    mpl.xticks(np.arange(.5,corr.shape[0]+.5),labels)\n",
    "    mpl.show()\n",
    "    mpl.clf();mpl.close() # reset pylab\n",
    "    return \n",
    "#------------------------------------------------------------------------------ \n",
    "def generateData(nObs,size0,size1,sigma1): # Time series of correlated variables \n",
    "    #1) generating some uncorrelated data \n",
    "    np.random.seed(seed=12345);\n",
    "    random.seed(12345)\n",
    "    x=np.random.normal(0,1,size=(nObs,size0)) # each row is a variable \n",
    "    #2) creating correlation between the variables \n",
    "    cols=[random.randint(0,size0-1)\n",
    "          for i in range(size1)]\n",
    "    y=x[:,cols]+np.random.normal(0,sigma1,size=(nObs,len(cols))) \n",
    "    x=np.append(x,y,axis=1) \n",
    "    x=pd.DataFrame(x,columns=range(1,x.shape[1]+1)) \n",
    "    return x,cols \n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "    #1) Generate correlated data\n",
    "####nObs,size0,size1,sigma1=10000,5,5,.25\n",
    "####x,cols=generateData(nObs,size0,size1,sigma1)\n",
    "#print [(j+1,size0+i) for (i,j) in enumerate(cols,1)]\n",
    "\n",
    "#1) SUSTITUYO EL GENERADOR DDE CORRALATION DATA POR EL RANGO DE TIEMPO DEL INDICE QUE QUIERO ANALIZAR\n",
    "#rent_periodo = np.log(df_close).diff().dropna()# lo que analizo son las rentabilidades #INCLUIDO POR MI\n",
    "#x = rent_periodo.iloc[::- 1,:]  # hay que darle la vuelta # hay que darle la vuelta #INCLUIDO POR MI\n",
    "\n",
    "##2) compute and plot correl matrix \n",
    "#cov,corr=x.cov(),x.corr() \n",
    "#plotCorrMatrix(corr,labels=corr.columns) #3) cluster\n",
    "#dist=correlDist(corr) \n",
    "#link=sch.linkage(dist,'single') # ESTO DA UN WARNING\n",
    "#mpl.figure(figsize=(15,6))\n",
    "#color = 'red'\n",
    "#sch.dendrogram(link)\n",
    "#mpl.legend(loc='upper left')\n",
    "#mpl.show()\n",
    "#sortIx=getQuasiDiag(link)\n",
    "#sortIx=corr.index[sortIx].tolist() # recover labels \n",
    "#df0=corr.loc[sortIx,sortIx] # reorder \n",
    "#plotCorrMatrix(df0,labels=df0.columns)\n",
    "#4) Capital allocation \n",
    "#hrp=getRecBipart(cov,sortIx) \n",
    "#print(hrp) #IMPORTANTE. ESTUDIALO BIEN\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "def calculate_portfolio_var(w,V):\n",
    "    w = np.matrix(w)\n",
    "    return (w*V*w.T)[0,0]\n",
    "\n",
    "def calculate_risk_contribution(w,V):\n",
    "    w = np.matrix(w)\n",
    "    sigma = np.sqrt(calculate_portfolio_var(w,V))\n",
    "    MRC = V*w.T\n",
    "    RC = np.multiply(MRC,w.T)/sigma\n",
    "    return RC\n",
    "\n",
    "def risk_budget_objective(x,pars):\n",
    "    V = pars[0]\n",
    "    x_t = pars[1] \n",
    "    sig_p =  np.sqrt(calculate_portfolio_var(x,V)) \n",
    "    risk_target = np.asmatrix(np.multiply(sig_p,x_t))\n",
    "    asset_RC = calculate_risk_contribution(x,V)\n",
    "    J = sum(np.square(asset_RC-risk_target.T))[0,0]*1000 \n",
    "    return J\n",
    "\n",
    "def total_weight_constraint(x):\n",
    "    return np.sum(x)-1.0\n",
    "\n",
    "def long_only_constraint(x):\n",
    "    return x\n",
    "#Max_Cash = 0.1\n",
    "\n",
    "#def Libor_constraint(x):\n",
    "#    return Max_Cash-x[6]\n",
    "\n",
    "\n",
    "\n",
    "#pd.set_option('max_rows', None)\n",
    "#pd.set_option('max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore') # me quita todos los warning por culpa de link=sch.linkage(dist,'single')\n",
    "\n",
    "\n",
    "\n",
    "#link=sch.linkage(dist,'single') data siempre un warning.\n",
    "#En https://stackoverflow.com/questions/60817473/warning-uncondensed-distance-matrix-in-python\n",
    "#Explican el pq y dice que se quite por las 3 siguietnes lineas\n",
    "from scipy.cluster.hierarchy import ClusterWarning\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", ClusterWarning)\n",
    "\n",
    "def HierarchicalRiskParity_Santander(dataset,link_viejo=[]): \n",
    "    hrp_bien=1\n",
    "    #2) compute and plot correl matrix \n",
    "    x=dataset\n",
    "    cov,corr=x.cov(),x.corr() \n",
    "    #####################################plotCorrMatrix(corr,labels=corr.columns) #3) cluster\n",
    "    dist=correlDist(corr)\n",
    "    \n",
    "    #Una vez me dio el error: The condensed distance matrix must contain only finite values. pq el CRH.I_0 \n",
    "    #tenia todos sus valores nan. Muy raro pa eso viene dle dataset que habia pasado los dropna.\n",
    "    #Pero para que no vuelva a pasarme le hagao eliminar todos los nan por filas\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        dist = dist.dropna(how='all') #elimina todos nan por filas; por si acaso. creo que no es necesario\n",
    "        #print(dist)\n",
    "        link=sch.linkage(dist,'single') # ESTO DA UN WARNING\n",
    "        #scipy.cluster.hierarchy.linkage(y, method='single', metric='euclidean', optimal_ordering=False)\n",
    "        #link=sch.linkage(dist, method='single', metric='euclidean', optimal_ordering=False)\n",
    "    except ValueError:\n",
    "    \n",
    "    #ValueError: The condensed distance matrix must contain only finite values.\n",
    "        link = link_viejo\n",
    "    try:\n",
    "        #####################################mpl.figure(figsize=(15,6))\n",
    "    #####################################color = 'red'\n",
    "        sch.dendrogram(link) ###################################\n",
    "    #####################################mpl.legend(loc='upper left')\n",
    "    #####################################mpl.show()\n",
    "        sortIx=getQuasiDiag(link)\n",
    "    #aveces salta esta funcion en IndexError: index 44 is out of bounds for axis 0 with size 0\n",
    "    #asi que lo que hago es que lo salte y copie lo que sucedio en la inversion anterior. Y me quito de lios.\n",
    "    \n",
    "        sortIx=corr.index[sortIx].tolist() # recover labels \n",
    "    #####################################df0=corr.loc[sortIx,sortIx] # reorder \n",
    "    #####################################plotCorrMatrix(df0,labels=df0.columns)\n",
    "    #4) Capital allocation \n",
    "        hrp=getRecBipart(cov,sortIx)\n",
    "        hrp_bien=1\n",
    "        \n",
    "    except:\n",
    "        # CUANDO LA GENERACION DE LA MATRIZ DEL CLUSTER DA ERRORES, QUE SIGA CON UN EQW\n",
    "        # me lo ha echo una vez\n",
    "        in_index = dataset.dropna().columns\n",
    "        #print(in_index)\n",
    "        alloc = 1 / (len(in_index)+0.00001) \n",
    "        hrp= pd.DataFrame(np.repeat(alloc,len(in_index)),index=in_index)\n",
    "        hrp_bien=0\n",
    "        print(\"SALTO LA MATRIZ\",hrp[0])\n",
    "      \n",
    "        \n",
    "\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #rent_periodo = np.log(df_close).diff().dropna()# lo que analizo son las rentabilidades\n",
    "    #rent_periodo =rent_periodo.iloc[-periodo_analisis:-1,:]\n",
    "    #dataset = rent_periodo.iloc[::- 1,:]  # hay que darle la vuelta\n",
    "    #print(dataset)\n",
    "    n= dataset.shape[1]# he puesto tan largo como activos hay\n",
    "    #print(n)\n",
    "\n",
    "    V = dataset.iloc[0:n].cov().values\n",
    "    x_t = [1/n]*n # inicializo equiponderado\n",
    "    w0 = [1/n]*n\n",
    "\n",
    "    cons = ({'type': 'eq', 'fun': total_weight_constraint},\n",
    "            #{'type': 'ineq', 'fun': Libor_constraint}, \n",
    "            {'type': 'ineq', 'fun': long_only_constraint})\n",
    "    res= minimize(risk_budget_objective, w0, args=[V,x_t], method='SLSQP', constraints=cons, options={'disp': False})\n",
    "    \n",
    "    w_rb = np.asmatrix(res.x)#son los pesos que hay que poner a todos los activos (los 34)\n",
    "    #print(\"w_rb\",w_rb) #son los pesos que hay que poner a todos los activos (los 34) en formato matriz\n",
    "    #print(\"res.x\",res.x) #son los pesos que hay que poner a todos los activos (los 34) en formato array\n",
    "    \n",
    "    resultado1=res.x\n",
    "    \n",
    "    #Aveces me ha dicho que suma mas de 100%\n",
    "    resultado1_s = pd.Series(resultado1)\n",
    "    resultado1_s = round(resultado1_s,6)\n",
    "    resultado1_s = round(resultado1_s/(resultado1_s.sum()+0.0001),6)\n",
    "    # asi me aseguro que nunca sea mayor a 1 # y me quita el error 'Asignacion mayor del 100%'\n",
    "    #print(\"alloc.sum()\",alloc.sum())\n",
    "    resultado1 = resultado1_s.tolist()    \n",
    "    #print(resultado1)\n",
    "    \n",
    "    resultado2 = getIVP(V).tolist()\n",
    "    resultado2_s = pd.Series(resultado2)\n",
    "    resultado2_s = round(resultado2_s,6)\n",
    "    resultado2_s = round(resultado2_s/(resultado2_s.sum()+0.0001),6)\n",
    "    resultado2 = resultado2_s.tolist() \n",
    "    \n",
    "\n",
    "    \n",
    "    if hrp_bien == 0:\n",
    "        resultado3 = list(hrp[0])\n",
    "    else:\n",
    "        resultado3 = hrp.tolist()\n",
    "    resultado3_s = pd.Series(resultado3)\n",
    "    resultado3_s = round(resultado3_s,6)\n",
    "    resultado3_s = round(resultado3_s/(resultado3_s.sum()+0.0001),6)\n",
    "    resultado3 = resultado3_s.tolist() \n",
    "    \n",
    "    resultado4 = hrp.index\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(resultado1,resultado2,resultado3,resultado4)\n",
    "    return resultado1,resultado2,resultado3,resultado4,link\n",
    "    \n",
    "    #resultado1 es RiskParity con el orden de acciones de dataset.columns\n",
    "    #resultado2 es IVP con el orden de acciones de dataset.columns. Implied Volatility Surface Parametrization\n",
    "    #resultado3 es HRP con el orden de acciones de resultado4.  HierarchicalRiskParity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9037b8-8fa3-4108-8de4-17367c45777a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc4e976-378f-4992-a991-c70e5784db5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='miax-gateway-jog4ew3z3q-ew.a.run.app', port=443): Max retries exceeded with url: /data/ticker_master?competi=mia_9&market=IBEX&key=AIzaSyDHpqtr1hgF2UpGxPtpv2iWKdxVsKCIr14 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000133E0441760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    175\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000133E0441760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='miax-gateway-jog4ew3z3q-ew.a.run.app', port=443): Max retries exceeded with url: /data/ticker_master?competi=mia_9&market=IBEX&key=AIzaSyDHpqtr1hgF2UpGxPtpv2iWKdxVsKCIr14 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000133E0441760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\2440494166.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[1;31m#inversion_1.run()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m \u001b[0minversion_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[0minversion_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[0minversion_4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\2440494166.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#1. Dias que no se debe invertir en IBEX, DAX y EUROSTOXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\2440494166.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdata_close_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mticker_master\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_ticker_master\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmarket\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mticker_master\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#itera por el ticker. A usado tambien iteritems si fuera pro columnas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mtck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17468\\3396637699.py\u001b[0m in \u001b[0;36mget_ticker_master\u001b[1;34m(self, market)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[1;34m'market'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmarket\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 'key': self.user_key}\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mtk_master\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmaestro_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtk_master\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'master'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \"\"\"\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    585\u001b[0m         }\n\u001b[0;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    563\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 565\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='miax-gateway-jog4ew3z3q-ew.a.run.app', port=443): Max retries exceeded with url: /data/ticker_master?competi=mia_9&market=IBEX&key=AIzaSyDHpqtr1hgF2UpGxPtpv2iWKdxVsKCIr14 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000133E0441760>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))"
     ]
    }
   ],
   "source": [
    "# CELDA PRINCIPAL DE EJECUCION DE PROGRAMA EN FASE DE INVERSION\n",
    "\n",
    "# CELDA QUE SE USARA PARA INVERTIR SEGUN LAS CONCLUSIONES EL PEQUENHO BACKTEST QUE HICE\n",
    "# EN EL DIA DE LA INVERSION, SE TIENE QUE ACTIVAR LAS CELDAS:\n",
    "# - CELDA: #CELDA DE INICIALIZACION DE class BMEApiHandler\n",
    "# - CELDA: #2. HierarchicalRiskParity del profesor del Santander. PARECE QUE FUNCIONA\n",
    "\n",
    "# EN DIA 5.9 TENGO QUE ACTUALIZAR ESTAS LINEAS SOLAMENTE:\n",
    "        #fecha_primer_dia=parse('27-07-2022',dayfirst=True)\n",
    "        ##fecha_primer_dia = parse('05-09-2022',dayfirst=True)# el que tengo que poner el dia que se empieza\n",
    "\n",
    "#SEGUN LAS CONCUSIONES DE LOS DIAS QUE TENGA QUE INVERTIR, SOLO ACTIVO LAS LINEAS inversion_x.run() EL DIA QUE \n",
    "#EL PROGRAMA ME HA DICHO QUE INVIERTA EN ESA INVERSION ESE DIA. y LO TRAQUEO CON EL EXCEL TABLA DE SEGUIMIENTO DIAS INVERSION EJERCICIO 3\n",
    "#SE PODRIA AUTOMATIZAR EN EL FUTURO COMO FERNANDO NOS EXPLICO\n",
    "\n",
    "\n",
    "\n",
    "class HierarchicalRiskParityAlgo_Invertir:\n",
    "    \n",
    "    def __init__(self, market, algo_tag, rbal_days,periodo_analisis,empezar_simulacion,method):\n",
    "        self.market = market\n",
    "        self.algo_tag = algo_tag\n",
    "        self.rbal_days = rbal_days\n",
    "        self.periodo_analisis = periodo_analisis\n",
    "        self.api_handler = BMEApiHandler()\n",
    "        self.df_close = None # lo defino vacio y en get_data hago la asignacion\n",
    "        self.df_close_benchmark = None \n",
    "        self.empezar_simulacion = empezar_simulacion\n",
    "        self.method = method\n",
    "    \n",
    "    def get_data(self):\n",
    "        data_close_dict = {}\n",
    "        ticker_master = self.api_handler.get_ticker_master(market=self.market)\n",
    "        for idx, row in ticker_master.iterrows(): #itera por el ticker. A usado tambien iteritems si fuera pro columnas\n",
    "            tck = row.ticker\n",
    "            ####print(tck)  ## Luego lo pongo. Lo que quitado para que el error me apareciera más limpio\n",
    "            close_data = self.api_handler.get_close_data(self.market, tck) #obtenemos el close data del tck delmercado\n",
    "            data_close_dict[tck] = close_data # Lo guardamos como un diccionario por cada iteracion \n",
    "        self.df_close = pd.DataFrame(data_close_dict) # y luego del dict lo pasamos a un df\n",
    "        return self.df_close\n",
    "    \n",
    "    def get_data_benchmark(self):\n",
    "        data_close_dict_benchmark = {}\n",
    "        tck_benchmark = 'benchmark'\n",
    "        close_data_benchmark = self.api_handler.get_close_data(self.market, tck_benchmark)\n",
    "        data_close_dict_benchmark[tck_benchmark] = close_data_benchmark\n",
    "        self.df_close_benchmark = pd.DataFrame(data_close_dict_benchmark)\n",
    "        return self.df_close_benchmark\n",
    "    \n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.get_data() \n",
    "\n",
    "        #1. Dias que no se debe invertir en IBEX, DAX y EUROSTOXX\n",
    "        #Cambio de hora(+2 dias mas) + festivo bolsa Madrid + no invierto los fines de semana para el IBEX, DAX y EUROSTOXX segun internet\n",
    "        #fecha_primer_dia=parse('27-07-2022',dayfirst=True)\n",
    "        fecha_primer_dia = parse('05-10-2022',dayfirst=True)# el que tengo que poner el dia que se empieza\n",
    "        fecha_ultimo_dia = parse('31-03-2023')\n",
    "        dias_posibles_a_invertir =list(pd.date_range(fecha_primer_dia, fecha_ultimo_dia))\n",
    "        a= list(pd.date_range(fecha_primer_dia, fecha_ultimo_dia, freq='B').strftime('%Y-%m-%d')) \n",
    "        b=['2022-10-30','2022-10-31','2022-11-01','2023-03-26','2023-03-27','2023-03-28','2023-03-29','2022-12-26']\n",
    "        puedo_invertir = sorted(pd.to_datetime(list(set(a) - set(b))))\n",
    "        \n",
    "        puedo_invertir_date=[]\n",
    "        for d in range(0,len(puedo_invertir)-1):\n",
    "           puedo_invertir_date.append(puedo_invertir[d].date())\n",
    "        puedo_invertir_date # los dias con los que si puedo invertir\n",
    "        \n",
    "        now = parse(datetime.now().strftime('%Y-%m-%d')).date() \n",
    "        \n",
    "        i=now\n",
    "        try:\n",
    "            puedo_invertir_date.index(i) # Con el error de este determino si puedo invertir o no\n",
    "            \n",
    "            \n",
    "\n",
    "            #2. Descargo los datos antiguos para hacer el estudio\n",
    "            link=[]\n",
    "            \n",
    "            data = self.df_close.iloc[self.df_close.shape[0]-self.periodo_analisis:,:]#.iterrows()\n",
    "            fecha = self.df_close.index[-1]\n",
    "            \n",
    "            in_index = data.dropna().index\n",
    "            #Y que pasa si se hizo el reajuste de indice en ese periodo? Que si en la columa hay algun NAN, que me quite toda la columna\n",
    "            \n",
    "            data = data.dropna(how='all') #elimina todos nan por filas. Serian los festivos.\n",
    "            data = data.dropna(axis=1)# eliminamos todas las columnas que tengan algun nan. Pq es que en ese periodo se ha metido o salido del indice\n",
    "            data = data.fillna(method = 'bfill') #rellena. No seria neecsario pero por si acaso             \n",
    "            data = data.fillna(method = 'ffill') #rellena. No seria neecsario pero por si acaso \n",
    "            data = data[::-1]\n",
    "            rent_periodo = np.log(data).diff()\n",
    "            dataset = rent_periodo\n",
    "        \n",
    "        \n",
    "            \n",
    "            alloc1, alloc_2, alloc_3, alloc_4,link= HierarchicalRiskParity_Santander(dataset,link) \n",
    "            now = datetime.now()\n",
    "            str_date = now.strftime('%Y-%m-%d')\n",
    "            #str_date = fecha.strftime('%Y-%m-%d')            \n",
    "            \n",
    "            if self.method ==  'RiskParity':\n",
    "                alloc = alloc1\n",
    "                acciones = dataset.columns  \n",
    "                allocation = [{'ticker': acciones[i],'alloc': alloc[i]} for i in range(len(alloc))]\n",
    "                self.api_handler.send_alloc(self.algo_tag, self.market, str_date, allocation)\n",
    "                print(self.algo_tag,'-', self.market,'-',self.method,':',\"Hoy se puede invertir\",i,\"El proximo dia que te toca invertir es \", i + timedelta(self.rbal_days))\n",
    "                #print('Allocation enviado hoy es con metodo RiskParity:',allocation)\n",
    "                allocs = pd.DataFrame(allocation)\n",
    "                allocs.set_index('ticker', inplace=True)\n",
    "                print('Allocation enviado hoy es con metodo RiskParity:',allocs)\n",
    "                print('La suma de todos los pesos en todos los valores suma:', allocs.alloc.sum())\n",
    "                \n",
    "            if self.method ==  'IVP':\n",
    "                alloc = alloc_2\n",
    "                acciones = dataset.columns\n",
    "                allocation = [{'ticker': acciones[i],'alloc': alloc[i]} for i in range(len(alloc))]\n",
    "                self.api_handler.send_alloc(self.algo_tag, self.market, str_date, allocation)\n",
    "                print(self.algo_tag,'-', self.market,'-',self.method,':',\"Hoy se puede invertir\",i,\"El proximo dia que te toca invertir es \", i + timedelta(self.rbal_days))\n",
    "                #print('Allocation enviado hoy es con metodo IVP:',allocation)\n",
    "                allocs = pd.DataFrame(allocation)\n",
    "                allocs.set_index('ticker', inplace=True)\n",
    "                print('Allocation enviado hoy es con metodo IVP:',allocs)\n",
    "                print('La suma de todos los pesos en todos los valores suma:', allocs.alloc.sum())\n",
    "                \n",
    "            if self.method ==  'HierarchicalRiskParity':\n",
    "                alloc = alloc_3\n",
    "                acciones = alloc_4            \n",
    "                allocation = [{'ticker': acciones[i],'alloc': alloc[i]} for i in range(len(alloc))]\n",
    "                self.api_handler.send_alloc(self.algo_tag, self.market, str_date, allocation)            \n",
    "                print(self.algo_tag,'-', self.market,'-',self.method,':',\"Hoy se puede invertir\",i,\"El proximo dia que te toca invertir es \", i + timedelta(self.rbal_days))\n",
    "                #print('Allocation enviado hoy es con metodo HierarchicalRiskParity:',allocation)\n",
    "                allocs = pd.DataFrame(allocation)\n",
    "                allocs.set_index('ticker', inplace=True)\n",
    "                print('Allocation enviado hoy es con metodo HierarchicalRiskParity:',allocs)\n",
    "                print('La suma de todos los pesos en todos los valores suma:', allocs.alloc.sum())\n",
    "                \n",
    "            if self.method ==  'EQW':\n",
    "                in_index=dataset.columns\n",
    "                alloc = 1 / (len(in_index)+0.00001) # le he metido  +0.00001 para que nunca me diga que supera el 100% de inversion maxima           \n",
    "                allocation = [{'ticker': tk, 'alloc': alloc}for tk in in_index]\n",
    "                self.api_handler.send_alloc(self.algo_tag, self.market, str_date, allocation)\n",
    "                print(self.algo_tag,'-', self.market,'-',self.method,':',\"Hoy se puede invertir\",i,\"El proximo dia que te toca invertir es \", i + timedelta(self.rbal_days))            \n",
    "                #print('Allocation enviado hoy es con metodo EQW:',allocation)\n",
    "                allocs = pd.DataFrame(allocation)\n",
    "                allocs.set_index('ticker', inplace=True)\n",
    "                print('Allocation enviado hoy es con metodo EQW:',allocs)\n",
    "                print('La suma de todos los pesos en todos los valores suma:', allocs.alloc.sum())\n",
    "\n",
    "        except ValueError:\n",
    "            print(\"Hoy no se puede invertir\",i)\n",
    "            for j in range(1,10):\n",
    "                prox_dia= i + timedelta(j)\n",
    "                try:\n",
    "                    puedo_invertir_date.index(prox_dia)\n",
    "                    print(\"El proximo dia que te toca invertir es \", prox_dia)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    next\n",
    "                    #print(\"NI MANHANA TAMPOCO\")\n",
    "\n",
    "        \n",
    "        return data,fecha, rent_periodo,alloc1, alloc_2, alloc_3, alloc_4,link\n",
    "\n",
    "\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "inversion_1=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='IBEX',\n",
    "    algo_tag='fgallego_algo1',\n",
    "    rbal_days=80, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'RiskParity')\n",
    "inversion_2=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='IBEX',\n",
    "    algo_tag='fgallego_algo2',\n",
    "    rbal_days=30, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'IVP')\n",
    "inversion_3=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='IBEX',\n",
    "    algo_tag='fgallego_algo3',\n",
    "    rbal_days=30, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'HierarchicalRiskParity')\n",
    "\n",
    "inversion_4=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='DAX',\n",
    "    algo_tag='fgallego_algo1',\n",
    "    rbal_days=30, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'RiskParity')\n",
    "inversion_5=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='DAX',\n",
    "    algo_tag='fgallego_algo2',\n",
    "    rbal_days=40, # irrelevante\n",
    "    periodo_analisis = 40,\n",
    "    empezar_simulacion = 90,\n",
    "    method = 'IVP')\n",
    "inversion_6=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='DAX',\n",
    "    algo_tag='fgallego_algo3',\n",
    "    rbal_days=40, # irrelevante\n",
    "    periodo_analisis = 40,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'HierarchicalRiskParity')\n",
    "\n",
    "inversion_7=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='EUROSTOXX',\n",
    "    algo_tag='fgallego_algo1',\n",
    "    rbal_days=80, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'EQW')\n",
    "inversion_8=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='EUROSTOXX',\n",
    "    algo_tag='fgallego_algo2',\n",
    "    rbal_days=80, # irrelevante\n",
    "    periodo_analisis = 80,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'IVP')\n",
    "inversion_9=HierarchicalRiskParityAlgo_Invertir(\n",
    "    market='EUROSTOXX',\n",
    "    algo_tag='fgallego_algo3',\n",
    "    rbal_days=40, # irrelevante\n",
    "    periodo_analisis = 40,\n",
    "    empezar_simulacion = 90,#irrelevante\n",
    "    method = 'HierarchicalRiskParity')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#INVERTIR\n",
    "\n",
    "#inversion_1.run()\n",
    "inversion_2.run()\n",
    "inversion_3.run()\n",
    "inversion_4.run()\n",
    "#inversion_5.run()\n",
    "#inversion_6.run()\n",
    "#inversion_7.run()\n",
    "#inversion_8.run()\n",
    "#inversion_9.run()\n",
    "\n",
    "#Consultar las asignaciones de pesos registradas. VER QUE SE HA RECEPCIONADO EL VECTOR\n",
    "def allocs_to_frame(json_allocations): # lo convierte a df qae viene de un json\n",
    "    alloc_list = []\n",
    "    for json_alloc in json_allocations:\n",
    "        #print(json_alloc)\n",
    "        allocs = pd.DataFrame(json_alloc['allocations'])\n",
    "        allocs.set_index('ticker', inplace=True)\n",
    "        alloc_serie = allocs['alloc']\n",
    "        alloc_serie.name = json_alloc['date'] \n",
    "        alloc_list.append(alloc_serie)\n",
    "    all_alloc_df = pd.concat(alloc_list, axis=1).T\n",
    "    return all_alloc_df\n",
    "\n",
    "\n",
    "url_base = 'https://miax-gateway-jog4ew3z3q-ew.a.run.app'\n",
    "competi = 'mia_9'\n",
    "user_key = 'AIzaSyDHpqtr1hgF2UpGxPtpv2iWKdxVsKCIr14'\n",
    "url = f'{url_base}/participants/algo_allocations' #pode en json\n",
    "\n",
    "market='IBEX'\n",
    "algo_tag='fgallego_algo1'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "IBEX_fgallego_algo1 = allocs_to_frame(response.json())\n",
    "print('IBEX_fgallego_algo1',IBEX_fgallego_algo1)\n",
    "\n",
    "market='IBEX'\n",
    "algo_tag='fgallego_algo2'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "IBEX_fgallego_algo2 = allocs_to_frame(response.json())\n",
    "print('IBEX_fgallego_algo2',IBEX_fgallego_algo2)\n",
    "\n",
    "market='IBEX'\n",
    "algo_tag='fgallego_algo3'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "IBEX_fgallego_algo3 = allocs_to_frame(response.json())\n",
    "print('IBEX_fgallego_algo3',IBEX_fgallego_algo3)\n",
    "\n",
    "market='DAX'\n",
    "algo_tag='fgallego_algo1'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "DAX_fgallego_algo1 = allocs_to_frame(response.json())\n",
    "print('DAX_fgallego_algo1',DAX_fgallego_algo1)\n",
    "\n",
    "market='DAX'\n",
    "algo_tag='fgallego_algo2'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "DAX_fgallego_algo2 = allocs_to_frame(response.json())\n",
    "print('DAX_fgallego_algo2',DAX_fgallego_algo2)\n",
    "\n",
    "market='DAX'\n",
    "algo_tag='fgallego_algo3'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "DAX_fgallego_algo3 = allocs_to_frame(response.json())\n",
    "print('DAX_fgallego_algo3',DAX_fgallego_algo3)\n",
    "\n",
    "market='EUROSTOXX'\n",
    "algo_tag='fgallego_algo1'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "EUROSTOXX_fgallego_algo1 = allocs_to_frame(response.json())\n",
    "print('EUROSTOXX_fgallego_algo1',EUROSTOXX_fgallego_algo1)\n",
    "\n",
    "market='EUROSTOXX'\n",
    "algo_tag='fgallego_algo2'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "EUROSTOXX_fgallego_algo2 = allocs_to_frame(response.json())\n",
    "print('EUROSTOXX_fgallego_algo2',EUROSTOXX_fgallego_algo2)\n",
    "\n",
    "market='EUROSTOXX'\n",
    "algo_tag='fgallego_algo3'\n",
    "params = {'key': user_key,'competi': competi,'algo_tag': algo_tag,'market': market}\n",
    "response = requests.get(url, params)\n",
    "EUROSTOXX_fgallego_algo3 = allocs_to_frame(response.json())\n",
    "print('EUROSTOXX_fgallego_algo3',EUROSTOXX_fgallego_algo3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f474d3-201c-426b-aa51-e28406f2af8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b8a32-b82d-47ee-b3b4-d5fd65458986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefbc6b-2483-4718-a110-c565944ce39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
